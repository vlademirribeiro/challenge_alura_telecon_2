{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMX8M8TkvuOqeP+h+ny3ypq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vlademirribeiro/challenge_alura_telecon_2/blob/main/telecom2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Desafio Telecom X - Parte 2: Modelagem Preditiva de Churn"
      ],
      "metadata": {
        "id": "CnpG5219xWgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Propósito da Análise"
      ],
      "metadata": {
        "id": "aeurTg19xlQP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este notebook é a resposta ao desafio da Telecom X para a equipe de Machine Learning. O objetivo principal é desenvolver um modelo preditivo capaz de identificar clientes com alta probabilidade de cancelar seus serviços (churn). A análise se baseia em um conjunto de dados pré-processado, e o resultado final será um modelo treinado e avaliado, acompanhado de insights estratégicos para a empresa."
      ],
      "metadata": {
        "id": "XGnEuc9uxxq3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Roteiro do Projeto"
      ],
      "metadata": {
        "id": "MVVniVtwx8tq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O desenvolvimento deste projeto seguirá as seguintes etapas:\n",
        "\n",
        "* Configuração e Carregamento dos Dados: Preparação do ambiente de trabalho e importação das bibliotecas e do conjunto de dados.\n",
        "* Análise Exploratória dos Dados (EDA): Investigação inicial dos dados para entender a distribuição das variáveis, identificar padrões e formular hipóteses.\n",
        "* Pré-processamento e Preparação dos Dados: Tratamento das variáveis para que possam ser utilizadas pelos algoritmos de machine learning (encoding, normalização, etc.).\n",
        "* Modelagem de Machine Learning: Treinamento de múltiplos algoritmos de classificação para prever o churn.\n",
        "* Avaliação dos Modelos: Utilização de métricas de performance para escolher o modelo mais eficaz.\n",
        "* Análise de Resultados e Conclusões Estratégicas: Interpretação do modelo final para extrair insights de negócio e apresentar recomendações.\n"
      ],
      "metadata": {
        "id": "HE3N2AZIyBqs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Configuração e Carregamento dos Dados\n",
        "Nesta primeira etapa, vamos importar as bibliotecas essenciais para o projeto e carregar nosso conjunto de dados. A base de dados, no formato JSON, será carregada diretamente do repositório GitHub do projeto, garantindo a reprodutibilidade da análise."
      ],
      "metadata": {
        "id": "EXLNPqGSzSlK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "1b00InxWnf5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bibliotecas do Skit Learn\n",
        "from sklearn.model_selection import train_test_split #Utilizada para separar dados pra treino e teste\n",
        "from sklearn.preprocessing import StandardScaler #Utilizada para fazer a padronização dos dados\n",
        "from sklearn.preprocessing import LabelEncoder #Utilizada para fazer o OneHotEncoding\n",
        "from sklearn.metrics import accuracy_score #Utilizada para avaliar a acurácia do modelo preditivo\n",
        "from sklearn.neighbors import KNeighborsClassifier #Nosso Algoritmo para criação do modelo\n",
        "from imblearn import under_sampling, over_sampling #Utilizada para fazer o balanceamento de dados\n",
        "from imblearn.over_sampling import SMOTE #Utilizada para fazer o balanceamento de dados\n",
        "from sklearn.preprocessing import StandardScaler # Utilizado para fazer a normalização dos dados\n",
        "from sklearn.preprocessing import MinMaxScaler # Utilizado para fazer a normalização dos dados\n",
        "from sklearn.preprocessing import LabelEncoder # Utilizado para fazer o OneHotEncoding\n",
        "from sklearn.linear_model import LinearRegression # Algoritmo de Regressão Linear\n",
        "from sklearn.metrics import r2_score # Utilizado para medir a acuracia do modelo preditivo\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n"
      ],
      "metadata": {
        "id": "ZfxUKPRW08v0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/ingridcristh/challenge2-data-science/refs/heads/main/TelecomX_Data.json\"\n",
        "response = requests.get(url)\n",
        "data = response.json()\n"
      ],
      "metadata": {
        "id": "foqXGyI2nf9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convertendo para dataframe\n",
        "df = pd.DataFrame(data)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "HHT5qbZIngAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_normalizados = pd.json_normalize(data)\n",
        "dados_normalizados.head()"
      ],
      "metadata": {
        "id": "HxCapwHXngCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_normalizados.to_csv(\"TelecomX_Data.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"CSV criado com sucesso!\")"
      ],
      "metadata": {
        "id": "RIqMuovf3KWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_normalizados.shape"
      ],
      "metadata": {
        "id": "g5Nbmtr2ngEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_normalizados.info()"
      ],
      "metadata": {
        "id": "bo8R9wlGngGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dados_normalizados.columns.tolist())"
      ],
      "metadata": {
        "id": "4vQeUQPrqZe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_normalizados.drop(['customerID'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "TIG0oN85ngJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_fix = [\n",
        "    'internet.OnlineSecurity', 'internet.OnlineBackup', 'internet.DeviceProtection',\n",
        "    'internet.TechSupport', 'internet.StreamingTV', 'internet.StreamingMovies'\n",
        "]\n",
        "\n",
        "for col in cols_to_fix:\n",
        "    dados_normalizados[col] = dados_normalizados[col].replace('No internet service', 'No')"
      ],
      "metadata": {
        "id": "mjMLM-gRngMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_normalizados.head()"
      ],
      "metadata": {
        "id": "6uSwTKZntiT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_normalizados.isna().sum()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "iJ68WmcGtiRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_normalizados.describe()\n"
      ],
      "metadata": {
        "id": "WhfFs5H0tiPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_normalizados.nunique()"
      ],
      "metadata": {
        "id": "DxbDxUShtiNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variaveis_numericas = []\n",
        "\n",
        "for i in dados_normalizados.columns[0:22].tolist():\n",
        "\n",
        "    # Verifica se o tipo de dado da coluna atual é 'int64' ou 'float64' (números inteiros ou reais)\n",
        "    if dados_normalizados.dtypes[i] == 'int64' or dados_normalizados.dtypes[i] == 'float64':\n",
        "\n",
        "        # Imprime o nome da coluna e o tipo de dado dela\n",
        "        print(i, ':', dados_normalizados.dtypes[i])\n",
        "\n",
        "        # Adiciona o nome da coluna à lista de variáveis numéricas\n",
        "        variaveis_numericas.append(i)"
      ],
      "metadata": {
        "id": "H4rFxROvtiJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define o tamanho da figura em polegadas: largura = 14, altura = 5\n",
        "plt.rcParams[\"figure.figsize\"] = [14.00, 5.00]\n",
        "\n",
        "# Garante que os elementos do gráfico se ajustem automaticamente ao layout\n",
        "plt.rcParams[\"figure.autolayout\"] = True\n",
        "\n",
        "# Como temos 5 variáveis, podemos criar uma grade de 1 linha e 5 colunas\n",
        "f, axes = plt.subplots(1, 3)  # 1 linha e 5 colunas\n",
        "\n",
        "# Inicializa a posição dos gráficos\n",
        "coluna = 0\n",
        "\n",
        "# Percorre todas as variáveis numéricas selecionadas\n",
        "for i in variaveis_numericas[:5]:  # Seleciona as primeiras 5 variáveis numéricas\n",
        "    # Cria um boxplot para a variável i na posição [0][coluna] da grade\n",
        "    sns.boxplot(data=dados_normalizados, y=i, ax=axes[coluna])\n",
        "\n",
        "    # Avança para a próxima coluna\n",
        "    coluna += 1\n",
        "\n",
        "# Exibe todos os gráficos gerados\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6xNC-OkJtiFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista para armazenar as variáveis categóricas\n",
        "variaveis_categoricas = []\n",
        "\n",
        "# Itera sobre as colunas de 0 até a 47 (isso seleciona as primeiras 48 colunas)\n",
        "for i in dados_normalizados.columns[0:23]:  # Corrigindo a iteração para cada coluna\n",
        "    if dados_normalizados.dtypes[i] == 'object' or dados_normalizados.dtypes[i] == 'category':\n",
        "        # Imprime o nome da variável e o seu tipo\n",
        "        print(i, ':', dados_normalizados.dtypes[i])\n",
        "        # Adiciona a variável à lista de variáveis categóricas\n",
        "        variaveis_categoricas.append(i)\n",
        "\n",
        "\n",
        "# Exibe as variáveis categóricas identificadas\n",
        "print(\"Variáveis categóricas:\",len(variaveis_categoricas), variaveis_categoricas)"
      ],
      "metadata": {
        "id": "FHjvLTQEtiCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "\n",
        "def plot_categoricas(dados, variaveis, ncols=4, figsize=(15, 15)):\n",
        "    \"\"\"\n",
        "    Plota gráficos de contagem para variáveis categóricas.\n",
        "\n",
        "    :param dados: DataFrame com os dados normalizados\n",
        "    :param variaveis: lista de colunas categóricas\n",
        "    :param ncols: número de colunas na grade de gráficos\n",
        "    :param figsize: tamanho da figura\n",
        "    \"\"\"\n",
        "    n_plots = len(variaveis)\n",
        "    nrows = math.ceil(n_plots / ncols)\n",
        "\n",
        "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
        "    axes = axes.flatten()  # transforma em lista 1D para simplificar\n",
        "\n",
        "    for ax, var in zip(axes, variaveis):\n",
        "        sns.countplot(data=dados, x=var, ax=ax)\n",
        "        ax.set_title(var)\n",
        "\n",
        "    # Remove eixos extras (se sobrar espaço na grade)\n",
        "    for ax in axes[n_plots:]:\n",
        "        ax.remove()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_hWtxOJvth_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams[\"figure.figsize\"] = [15.00, 5.00]\n",
        "plt.rcParams[\"figure.autolayout\"] = True\n",
        "\n",
        "# Aqui definimos em quantas linhas e colunas queremos exibir os gráficos\n",
        "f, axes = plt.subplots(2, 3) #4 linhas e 3 colunas\n",
        "\n",
        "linha = 0\n",
        "coluna = 0\n",
        "\n",
        "for i in variaveis_numericas:\n",
        "    sns.histplot(data = dados_normalizados, x=i, ax=axes[linha][coluna])\n",
        "    coluna += 1\n",
        "    if coluna == 3:\n",
        "        linha += 1\n",
        "        coluna = 0\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PYI4Dputth9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_normalizados.head()"
      ],
      "metadata": {
        "id": "4RGoytI8th63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variaveis_categoricas"
      ],
      "metadata": {
        "id": "d6e3xSoHzHyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapa_binario = {'Yes': 1, 'No': 0, 'Female': 0, 'Male': 1}\n",
        "colunas_para_mapear = ['Churn', 'customer.gender', 'customer.Partner', 'customer.Dependents', 'phone.PhoneService', 'account.PaperlessBilling']\n",
        "\n",
        "for col in colunas_para_mapear:\n",
        "    # Apenas mapeia se a coluna ainda for do tipo 'object'\n",
        "    if dados_normalizados[col].dtype == 'object':\n",
        "        dados_normalizados[col] = dados_normalizados[col].map(mapa_binario)\n",
        "\n",
        "# Identifica colunas multinomiais que ainda são 'object'\n",
        "colunas_multinomiais = dados_normalizados.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Aplica One-Hot Encoding (get_dummies)\n",
        "dados = pd.get_dummies(dados_normalizados, columns=colunas_multinomiais, drop_first=True)\n",
        "\n",
        "print(\"Dados após One-Hot Encoding:\")\n",
        "dados.head()"
      ],
      "metadata": {
        "id": "GBdq1xGLzHvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos aplicar a normalização\n",
        "\n",
        "# Selecionando apenas colunas numéricas (exceto a variável target, se já estiver separada)\n",
        "colunas_numericas = dados_normalizados.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Inicializando o scaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Aplicando a normalização\n",
        "dados_normalizados[colunas_numericas] = scaler.fit_transform(dados[colunas_numericas])\n",
        "\n",
        "# Exibindo os dados normalizados\n",
        "dados.head()\n"
      ],
      "metadata": {
        "id": "UbTpxTQBzHsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr = dados_normalizados.corr(numeric_only=True)\n",
        "\n",
        "# Cria uma máscara para ocultar a parte superior da matriz (duplicada)\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "\n",
        "# Configuração da figura\n",
        "fig, ax = plt.subplots(figsize=(8, 10))\n",
        "\n",
        "# Heatmap estilizado\n",
        "sns.heatmap(\n",
        "    np.round(corr, 2),\n",
        "    mask=mask,               # Máscara triangular\n",
        "    cmap='RdBu',             # Mapa de cores contrastante\n",
        "    vmax=1, vmin=-1, center=0,\n",
        "    square=True,\n",
        "    linewidths=.5,\n",
        "    annot=True,              # Mostrar valores\n",
        "    annot_kws={\"size\": 10},   # Tamanho do texto\n",
        "    cbar_kws={\"shrink\": .5}   # Barra de cores menor\n",
        ")\n",
        "\n",
        "# Ajusta rótulos\n",
        "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
        "plt.yticks(rotation=0, fontsize=12)\n",
        "\n",
        "# Título\n",
        "plt.title('Matriz de Correlação das Variáveis', fontsize=18, pad=20)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Ny2A9JPfzHoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 10))\n",
        "\n",
        "# Calcula a matriz de correlação do DataFrame e filtra para mostrar apenas as correlações com 'Churn'\n",
        "# Ordena os valores para visualizar facilmente os fatores mais correlacionados (positiva ou negativamente)\n",
        "heatmap = sns.heatmap(\n",
        "    dados_normalizados.corr(numeric_only=True)[['Churn']].sort_values(by='Churn', ascending=False),\n",
        "    vmin=-1, vmax=1, annot=True, cmap='BrBG'\n",
        ")\n",
        "\n",
        "# Título do gráfico\n",
        "heatmap.set_title('Features Correlacionadas com Churn', fontdict={'fontsize': 18}, pad=16)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MDHAJGIkzHlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_normalizados.info()"
      ],
      "metadata": {
        "id": "VtvlaCirzHix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_normalizados.head()\n"
      ],
      "metadata": {
        "id": "4NJ5Ap8DzHf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Separar X e y do dataframe original (antes do SMOTE)\n",
        "X = dados_normalizados.drop('Churn', axis=1)\n",
        "y = dados_normalizados['Churn']\n"
      ],
      "metadata": {
        "id": "YL_aY0d4zHcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Dividir em dados de treino e teste PRIMEIRO\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.3, random_state=40)"
      ],
      "metadata": {
        "id": "DAXffAFm7kgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibe a distribuição normalizada da variável 'Churn' em percentual\n",
        "churn_distribution = dados_normalizados['Churn'].value_counts(normalize=True) * 100\n",
        "\n",
        "# Exibe os resultados com duas casas decimais\n",
        "print(churn_distribution.apply(lambda x: f'{x:.2f}%'))"
      ],
      "metadata": {
        "id": "iV_-5yKPzHZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Quantidade de NaN em y:\", y.isna().sum())\n",
        "print(\"Total de linhas em y:\", len(y))\n",
        "print(\"Proporção de NaN em y:\", y.isna().mean())\n",
        "\n",
        "print(\"\\nVerificando X:\")\n",
        "print(X.isna().sum())  # mostra colunas com NaN\n"
      ],
      "metadata": {
        "id": "ulhNKWYLBIaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape de X:\", X.shape)\n",
        "print(\"Shape de y:\", y.shape)\n",
        "\n",
        "# Se estiver usando treino/teste\n",
        "print(\"Shape de X_treino:\", X_treino.shape)\n",
        "print(\"Shape de y_treino:\", y_treino.shape)\n"
      ],
      "metadata": {
        "id": "Xl4Dqo88Bv6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibe a distribuição normalizada da variável 'Churn' em percentual\n",
        "churn_distribution = dados['Churn'].value_counts(normalize=True) * 100\n",
        "\n",
        "# Exibe os resultados com duas casas decimais\n",
        "print(churn_distribution.apply(lambda x: f'{x:.2f}%'))"
      ],
      "metadata": {
        "id": "gyI1eQIK5nR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Colunas numéricas → preencher com mediana\n",
        "num_cols = X.select_dtypes(include='number').columns\n",
        "X[num_cols] = X[num_cols].fillna(X[num_cols].median())\n",
        "\n",
        "# Colunas categóricas → preencher com moda\n",
        "cat_cols = X.select_dtypes(include='object').columns\n",
        "for col in cat_cols:\n",
        "    X[col] = X[col].fillna(X[col].mode()[0])\n",
        "\n",
        "# Tratar NaN do alvo e garantir 0/1\n",
        "if y.dtype.kind in 'O':  # Se alvo for string\n",
        "    y = y.fillna(y.mode()[0])\n",
        "    if set(y.unique()) == {'Yes','No'}:\n",
        "        y = y.map({'No':0,'Yes':1})\n",
        "else:\n",
        "    y = y.fillna(y.mode()[0]).astype(int)\n",
        "\n"
      ],
      "metadata": {
        "id": "AgTyqYTn4aqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Função de validação\n",
        "# =========================\n",
        "def validar_dados(X, y, etapa=\"pré-processamento\"):\n",
        "    print(f\"\\n🔎 Validando dados após etapa: {etapa}\")\n",
        "    print(f\"➡ Shape de X: {X.shape}\")\n",
        "    print(f\"➡ Shape de y: {y.shape}\")\n",
        "\n",
        "    if X.shape[0] == 0 or y.shape[0] == 0:\n",
        "        raise ValueError(f\"❌ Dataset vazio após {etapa}.\")\n",
        "\n",
        "    na_x = X.isna().sum()\n",
        "    if na_x.sum() > 0:\n",
        "        print(\"⚠️ Atenção: X contém NaN nas colunas abaixo:\")\n",
        "        print(na_x[na_x > 0])\n",
        "\n",
        "    if y.isna().sum() > 0:\n",
        "        print(f\"⚠️ Atenção: y contém {y.isna().sum()} NaN.\")\n",
        "\n",
        "    print(\"✅ Dados válidos!\")\n",
        "\n",
        "validar_dados(X, y, etapa=\"após tratamento de NaN\")"
      ],
      "metadata": {
        "id": "JnXf1WWpAeNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 5️⃣ Split treino/teste\n",
        "# =========================\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "validar_dados(X_treino, y_treino, etapa=\"train_test_split\")\n",
        "\n",
        "# =========================\n",
        "# 6️⃣ One-Hot Encoding nas colunas categóricas\n",
        "# =========================\n",
        "X_treino_enc = pd.get_dummies(X_treino, drop_first=True)\n",
        "X_teste_enc  = pd.get_dummies(X_teste, drop_first=True)\n",
        "\n",
        "# Garantir que as colunas do teste sejam iguais às do treino\n",
        "X_teste_enc = X_teste_enc.reindex(columns=X_treino_enc.columns, fill_value=0)\n",
        "\n"
      ],
      "metadata": {
        "id": "Oe93IFwR4akk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#⃣⃣ Distribuição original do alvo\n",
        "# =========================\n",
        "print(\"\\n🔹 Distribuição de Churn antes do SMOTE:\")\n",
        "print(y_treino.value_counts(normalize=True) * 100)"
      ],
      "metadata": {
        "id": "Ef5pNFax4aKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8️⃣ Aplicar SMOTE\n",
        "# =========================\n",
        "smote = SMOTE(random_state=42)\n",
        "X_treino_res, y_treino_res = smote.fit_resample(X_treino_enc, y_treino)"
      ],
      "metadata": {
        "id": "O2UM5iaV_n9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Distribuição após SMOTE\n",
        "# =========================\n",
        "print(\"\\n🔹 Distribuição de Churn após SMOTE:\")\n",
        "print(pd.Series(y_treino_res).value_counts(normalize=True) * 100)\n",
        "\n",
        "print(f\"\\n✅ SMOTE aplicado! Novo shape treino: {X_treino_res.shape}\")"
      ],
      "metadata": {
        "id": "N3thWir6_n0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "kVals = range(3, 10, 2)\n",
        "acuracias = []\n",
        "start = time.time()\n",
        "\n",
        "for k in kVals:\n",
        "    modeloKNN = KNeighborsClassifier(n_neighbors=k)\n",
        "    modeloKNN.fit(X_treino_res, y_treino_res)\n",
        "\n",
        "    score = modeloKNN.score(X_teste_enc, y_teste)  # usa teste codificado!\n",
        "    print(f\"Com valor de k = {k}, a acurácia é = {score * 100:.2f}%\")\n",
        "    acuracias.append(score)\n",
        "\n",
        "# Melhor valor de k\n",
        "i = np.argmax(acuracias)\n",
        "print(f\"\\n🔥 O valor de k = {kVals[i]} alcançou a mais alta acurácia de {acuracias[i] * 100:.2f}% nos dados de validação!\")\n"
      ],
      "metadata": {
        "id": "z5ZLcJp-_nbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lr = LogisticRegression(random_state=42, max_iter=1000)  # aumento de iterações p/ evitar warning\n",
        "lr.fit(X_treino_res, y_treino_res)\n",
        "\n",
        "\n",
        "y_pred_lr = lr.predict(X_teste_enc)             # usa teste codificado\n",
        "y_prob_lr = lr.predict_proba(X_teste_enc)[:, 1] # probabilidades para curva ROC\n",
        "\n",
        "\n",
        "print(\"=== 📊 Regressão Logística ===\")\n",
        "print(\"Acurácia:\", round(accuracy_score(y_teste, y_pred_lr), 4))\n",
        "print(\"ROC AUC:\", round(roc_auc_score(y_teste, y_prob_lr), 4))\n",
        "print(\"\\nMatriz de Confusão:\\n\", confusion_matrix(y_teste, y_pred_lr))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_teste, y_pred_lr))\n"
      ],
      "metadata": {
        "id": "vuAPsMSKDO41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# =========================\n",
        "# 2️⃣ Grade de parâmetros\n",
        "# =========================\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],       # número de árvores\n",
        "    'max_depth': [10, 20],                 # profundidade máxima da árvore\n",
        "    'min_samples_split': [2, 5, 10],       # mínimo de amostras para dividir um nó\n",
        "    'min_samples_leaf': [1, 2, 4],         # mínimo de amostras por folha\n",
        "    'max_features': ['sqrt', 'log2']       # como selecionar features em cada divisão\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# 3️⃣ Busca em grade (GridSearchCV)\n",
        "# =========================\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,                     # 5-fold cross validation\n",
        "    scoring='roc_auc',        # métrica alvo\n",
        "    n_jobs=-1,                # usar todos os núcleos disponíveis\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# 4️⃣ Treinamento\n",
        "# =========================\n",
        "grid_search.fit(X_treino_res, y_treino_res)\n",
        "\n",
        "print(\"\\n=== 🌳 Random Forest com GridSearchCV ===\")\n",
        "print(\"Melhores parâmetros encontrados:\", grid_search.best_params_)\n",
        "print(\"Melhor pontuação ROC AUC (validação cruzada):\", round(grid_search.best_score_, 4))\n",
        "\n",
        "# =========================\n",
        "# 5️⃣ Avaliação final no conjunto de teste\n",
        "# =========================\n",
        "best_rf = grid_search.best_estimator_  # melhor modelo encontrado\n",
        "\n",
        "# Previsões no conjunto de teste\n",
        "y_pred_rf = best_rf.predict(X_teste_enc)\n",
        "y_prob_rf = best_rf.predict_proba(X_teste_enc)[:, 1]\n",
        "\n",
        "print(\"\\nAvaliação no conjunto de teste:\")\n",
        "print(\"Acurácia:\", round(accuracy_score(y_teste, y_pred_rf), 4))\n",
        "print(\"ROC AUC:\", round(roc_auc_score(y_teste, y_prob_rf), 4))\n",
        "print(\"\\nMatriz de Confusão:\\n\", confusion_matrix(y_teste, y_pred_rf))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_teste, y_pred_rf))"
      ],
      "metadata": {
        "id": "PpbI5UHwEMoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 5️⃣ Avaliação final no conjunto de teste\n",
        "# =========================\n",
        "best_rf = grid_search.best_estimator_  # melhor modelo encontrado\n",
        "\n",
        "# Previsões no conjunto de teste\n",
        "y_pred_rf = best_rf.predict(X_teste_enc)\n",
        "y_prob_rf = best_rf.predict_proba(X_teste_enc)[:, 1]\n",
        "\n",
        "print(\"\\nAvaliação no conjunto de teste:\")\n",
        "print(\"Acurácia:\", round(accuracy_score(y_teste, y_pred_rf), 4))\n",
        "print(\"ROC AUC:\", round(roc_auc_score(y_teste, y_prob_rf), 4))\n",
        "print(\"\\nMatriz de Confusão:\\n\", confusion_matrix(y_teste, y_pred_rf))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_teste, y_pred_rf))\n",
        "\n",
        "# =========================\n",
        "# 6️⃣ Resumo do melhor modelo\n",
        "# =========================\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\" 🎯 MELHOR MODELO PARA ESTA ANÁLISE 🎯 \".center(60, \" \"))\n",
        "print(\"=\"*60)\n",
        "print(\"\\n📌 Modelo escolhido: RandomForestClassifier\")\n",
        "print(f\"🔹 Melhores parâmetros: {best_params}\")\n",
        "print(f\"📊 Melhor ROC AUC: {best_score:.4f}\")\n",
        "print(\"\\n✅ Este modelo apresentou a melhor performance entre os testados e será utilizado para as próximas etapas da análise.\")\n",
        "print(\"=\"*60)\n"
      ],
      "metadata": {
        "id": "wcGSA-ykHJq5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}