{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNR+U1hrfgmfcRLyTTusLgl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vlademirribeiro/challenge_alura_telecon_2/blob/main/telecom2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "1b00InxWnf5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bibliotecas do Skit Learn\n",
        "from sklearn.model_selection import train_test_split #Utilizada para separar dados pra treino e teste\n",
        "from sklearn.preprocessing import StandardScaler #Utilizada para fazer a padroniza√ß√£o dos dados\n",
        "from sklearn.preprocessing import LabelEncoder #Utilizada para fazer o OneHotEncoding\n",
        "from sklearn.metrics import accuracy_score #Utilizada para avaliar a acur√°cia do modelo preditivo\n",
        "from sklearn.neighbors import KNeighborsClassifier #Nosso Algoritmo para cria√ß√£o do modelo\n",
        "from imblearn import under_sampling, over_sampling #Utilizada para fazer o balanceamento de dados\n",
        "from imblearn.over_sampling import SMOTE #Utilizada para fazer o balanceamento de dados\n",
        "from sklearn.preprocessing import StandardScaler # Utilizado para fazer a normaliza√ß√£o dos dados\n",
        "from sklearn.preprocessing import MinMaxScaler # Utilizado para fazer a normaliza√ß√£o dos dados\n",
        "from sklearn.preprocessing import LabelEncoder # Utilizado para fazer o OneHotEncoding\n",
        "from sklearn.linear_model import LinearRegression # Algoritmo de Regress√£o Linear\n",
        "from sklearn.metrics import r2_score # Utilizado para medir a acuracia do modelo preditivo\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "ZfxUKPRW08v0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/ingridcristh/challenge2-data-science/refs/heads/main/TelecomX_Data.json\"\n",
        "response = requests.get(url)\n",
        "data = response.json()\n"
      ],
      "metadata": {
        "id": "foqXGyI2nf9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convertendo para dataframe\n",
        "df = pd.DataFrame(data)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "HHT5qbZIngAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_normalizados = pd.json_normalize(data)\n",
        "dados_normalizados.head()"
      ],
      "metadata": {
        "id": "HxCapwHXngCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_normalizados.shape"
      ],
      "metadata": {
        "id": "g5Nbmtr2ngEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_normalizados.info()"
      ],
      "metadata": {
        "id": "bo8R9wlGngGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dados_normalizados.columns.tolist())"
      ],
      "metadata": {
        "id": "4vQeUQPrqZe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_normalizados.drop(['customerID'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "TIG0oN85ngJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_fix = [\n",
        "    'internet.OnlineSecurity', 'internet.OnlineBackup', 'internet.DeviceProtection',\n",
        "    'internet.TechSupport', 'internet.StreamingTV', 'internet.StreamingMovies'\n",
        "]\n",
        "\n",
        "for col in cols_to_fix:\n",
        "    dados_normalizados[col] = dados_normalizados[col].replace('No internet service', 'No')"
      ],
      "metadata": {
        "id": "mjMLM-gRngMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_normalizados.head()"
      ],
      "metadata": {
        "id": "6uSwTKZntiT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_normalizados.isna().sum()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "iJ68WmcGtiRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_normalizados.describe()\n",
        ""
      ],
      "metadata": {
        "id": "WhfFs5H0tiPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_normalizados.nunique()"
      ],
      "metadata": {
        "id": "DxbDxUShtiNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variaveis_numericas = []\n",
        "\n",
        "for i in dados_normalizados.columns[0:22].tolist():\n",
        "\n",
        "    # Verifica se o tipo de dado da coluna atual √© 'int64' ou 'float64' (n√∫meros inteiros ou reais)\n",
        "    if dados_normalizados.dtypes[i] == 'int64' or dados_normalizados.dtypes[i] == 'float64':\n",
        "\n",
        "        # Imprime o nome da coluna e o tipo de dado dela\n",
        "        print(i, ':', dados_normalizados.dtypes[i])\n",
        "\n",
        "        # Adiciona o nome da coluna √† lista de vari√°veis num√©ricas\n",
        "        variaveis_numericas.append(i)"
      ],
      "metadata": {
        "id": "H4rFxROvtiJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define o tamanho da figura em polegadas: largura = 14, altura = 5\n",
        "plt.rcParams[\"figure.figsize\"] = [14.00, 5.00]\n",
        "\n",
        "# Garante que os elementos do gr√°fico se ajustem automaticamente ao layout\n",
        "plt.rcParams[\"figure.autolayout\"] = True\n",
        "\n",
        "# Como temos 5 vari√°veis, podemos criar uma grade de 1 linha e 5 colunas\n",
        "f, axes = plt.subplots(1, 3)  # 1 linha e 5 colunas\n",
        "\n",
        "# Inicializa a posi√ß√£o dos gr√°ficos\n",
        "coluna = 0\n",
        "\n",
        "# Percorre todas as vari√°veis num√©ricas selecionadas\n",
        "for i in variaveis_numericas[:5]:  # Seleciona as primeiras 5 vari√°veis num√©ricas\n",
        "    # Cria um boxplot para a vari√°vel i na posi√ß√£o [0][coluna] da grade\n",
        "    sns.boxplot(data=dados_normalizados, y=i, ax=axes[coluna])\n",
        "\n",
        "    # Avan√ßa para a pr√≥xima coluna\n",
        "    coluna += 1\n",
        "\n",
        "# Exibe todos os gr√°ficos gerados\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6xNC-OkJtiFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista para armazenar as vari√°veis categ√≥ricas\n",
        "variaveis_categoricas = []\n",
        "\n",
        "# Itera sobre as colunas de 0 at√© a 47 (isso seleciona as primeiras 48 colunas)\n",
        "for i in dados_normalizados.columns[0:23]:  # Corrigindo a itera√ß√£o para cada coluna\n",
        "    if dados_normalizados.dtypes[i] == 'object' or dados_normalizados.dtypes[i] == 'category':\n",
        "        # Imprime o nome da vari√°vel e o seu tipo\n",
        "        print(i, ':', dados_normalizados.dtypes[i])\n",
        "        # Adiciona a vari√°vel √† lista de vari√°veis categ√≥ricas\n",
        "        variaveis_categoricas.append(i)\n",
        "\n",
        "\n",
        "# Exibe as vari√°veis categ√≥ricas identificadas\n",
        "print(\"Vari√°veis categ√≥ricas:\",len(variaveis_categoricas), variaveis_categoricas)"
      ],
      "metadata": {
        "id": "FHjvLTQEtiCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "\n",
        "def plot_categoricas(dados, variaveis, ncols=4, figsize=(15, 15)):\n",
        "    \"\"\"\n",
        "    Plota gr√°ficos de contagem para vari√°veis categ√≥ricas.\n",
        "\n",
        "    :param dados: DataFrame com os dados normalizados\n",
        "    :param variaveis: lista de colunas categ√≥ricas\n",
        "    :param ncols: n√∫mero de colunas na grade de gr√°ficos\n",
        "    :param figsize: tamanho da figura\n",
        "    \"\"\"\n",
        "    n_plots = len(variaveis)\n",
        "    nrows = math.ceil(n_plots / ncols)\n",
        "\n",
        "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
        "    axes = axes.flatten()  # transforma em lista 1D para simplificar\n",
        "\n",
        "    for ax, var in zip(axes, variaveis):\n",
        "        sns.countplot(data=dados, x=var, ax=ax)\n",
        "        ax.set_title(var)\n",
        "\n",
        "    # Remove eixos extras (se sobrar espa√ßo na grade)\n",
        "    for ax in axes[n_plots:]:\n",
        "        ax.remove()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Exemplo de uso\n",
        "# plot_categoricas(dados_normalizados, variaveis_categoricas)\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "# Com este comando iremos exibir todos gr√°ficos de todas colunas de uma vez s√≥ para facilitar nossa an√°lise.\n",
        "\n",
        "# Aqui definimos o tamanho da tela para exibi√ß√£o dos gr√°ficos\n",
        "plt.rcParams[\"figure.figsize\"] = [15.00, 15.00]\n",
        "plt.rcParams[\"figure.autolayout\"] = True\n",
        "\n",
        "# Aqui definimos em quantas linhas e colunas queremos exibir os gr√°ficos\n",
        "# Usando 5 linhas e 4 colunas para acomodar 17 gr√°ficos\n",
        "f, axes = plt.subplots(4, 4)  # 5 linhas e 4 colunas (total de 20 gr√°ficos)\n",
        "\n",
        "# Inicializa a posi√ß√£o dos gr√°ficos\n",
        "linha = 0\n",
        "coluna = 0\n",
        "\n",
        "# Itera sobre as vari√°veis categ√≥ricas\n",
        "for i in variaveis_categoricas:\n",
        "    # Verifica se a posi√ß√£o de coluna excedeu o n√∫mero de colunas (4)\n",
        "    sns.countplot(data=dados_normalizados, x=i, ax=axes[linha][coluna])\n",
        "\n",
        "    coluna += 1\n",
        "    if coluna == 4:  # Quando atingir a 4¬™ coluna, vai para a pr√≥xima linha\n",
        "        linha += 1\n",
        "        coluna = 0\n",
        "\n",
        "# Ajusta o layout para que todos os gr√°ficos sejam exibidos corretamente\n",
        "plt.tight_layout()\n",
        "\n",
        "# Exibe os gr√°ficos\n",
        "plt.show()\n",
        "'''"
      ],
      "metadata": {
        "id": "_hWtxOJvth_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams[\"figure.figsize\"] = [15.00, 5.00]\n",
        "plt.rcParams[\"figure.autolayout\"] = True\n",
        "\n",
        "# Aqui definimos em quantas linhas e colunas queremos exibir os gr√°ficos\n",
        "f, axes = plt.subplots(2, 3) #4 linhas e 3 colunas\n",
        "\n",
        "linha = 0\n",
        "coluna = 0\n",
        "\n",
        "for i in variaveis_numericas:\n",
        "    sns.histplot(data = dados_normalizados, x=i, ax=axes[linha][coluna])\n",
        "    coluna += 1\n",
        "    if coluna == 3:\n",
        "        linha += 1\n",
        "        coluna = 0\n",
        "\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "PYI4Dputth9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_normalizados.head()"
      ],
      "metadata": {
        "id": "4RGoytI8th63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variaveis_categoricas"
      ],
      "metadata": {
        "id": "d6e3xSoHzHyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapa_binario = {'Yes': 1, 'No': 0, 'Female': 0, 'Male': 1}\n",
        "colunas_para_mapear = ['Churn', 'customer.gender', 'customer.Partner', 'customer.Dependents', 'phone.PhoneService', 'account.PaperlessBilling']\n",
        "\n",
        "for col in colunas_para_mapear:\n",
        "    # Apenas mapeia se a coluna ainda for do tipo 'object'\n",
        "    if dados_normalizados[col].dtype == 'object':\n",
        "        dados_normalizados[col] = dados_normalizados[col].map(mapa_binario)\n",
        "\n",
        "# Identifica colunas multinomiais que ainda s√£o 'object'\n",
        "colunas_multinomiais = dados_normalizados.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Aplica One-Hot Encoding (get_dummies)\n",
        "dados = pd.get_dummies(dados_normalizados, columns=colunas_multinomiais, drop_first=True)\n",
        "\n",
        "print(\"Dados ap√≥s One-Hot Encoding:\")\n",
        "dados.head()"
      ],
      "metadata": {
        "id": "GBdq1xGLzHvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos aplicar a normaliza√ß√£o\n",
        "\n",
        "# Selecionando apenas colunas num√©ricas (exceto a vari√°vel target, se j√° estiver separada)\n",
        "colunas_numericas = dados_normalizados.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Inicializando o scaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Aplicando a normaliza√ß√£o\n",
        "dados_normalizados[colunas_numericas] = scaler.fit_transform(dados[colunas_numericas])\n",
        "\n",
        "# Exibindo os dados normalizados\n",
        "dados.head()\n",
        ""
      ],
      "metadata": {
        "id": "UbTpxTQBzHsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr = dados_normalizados.corr(numeric_only=True)\n",
        "\n",
        "# Cria uma m√°scara para ocultar a parte superior da matriz (duplicada)\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "\n",
        "# Configura√ß√£o da figura\n",
        "fig, ax = plt.subplots(figsize=(8, 10))\n",
        "\n",
        "# Heatmap estilizado\n",
        "sns.heatmap(\n",
        "    np.round(corr, 2),\n",
        "    mask=mask,               # M√°scara triangular\n",
        "    cmap='RdBu',             # Mapa de cores contrastante\n",
        "    vmax=1, vmin=-1, center=0,\n",
        "    square=True,\n",
        "    linewidths=.5,\n",
        "    annot=True,              # Mostrar valores\n",
        "    annot_kws={\"size\": 10},   # Tamanho do texto\n",
        "    cbar_kws={\"shrink\": .5}   # Barra de cores menor\n",
        ")\n",
        "\n",
        "# Ajusta r√≥tulos\n",
        "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
        "plt.yticks(rotation=0, fontsize=12)\n",
        "\n",
        "# T√≠tulo\n",
        "plt.title('Matriz de Correla√ß√£o das Vari√°veis', fontsize=18, pad=20)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Ny2A9JPfzHoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 10))\n",
        "\n",
        "# Calcula a matriz de correla√ß√£o do DataFrame e filtra para mostrar apenas as correla√ß√µes com 'Churn'\n",
        "# Ordena os valores para visualizar facilmente os fatores mais correlacionados (positiva ou negativamente)\n",
        "heatmap = sns.heatmap(\n",
        "    dados_normalizados.corr(numeric_only=True)[['Churn']].sort_values(by='Churn', ascending=False),\n",
        "    vmin=-1, vmax=1, annot=True, cmap='BrBG'\n",
        ")\n",
        "\n",
        "# T√≠tulo do gr√°fico\n",
        "heatmap.set_title('Features Correlacionadas com Churn', fontdict={'fontsize': 18}, pad=16)\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "MDHAJGIkzHlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_normalizados.info()"
      ],
      "metadata": {
        "id": "VtvlaCirzHix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_normalizados.head()\n"
      ],
      "metadata": {
        "id": "4NJ5Ap8DzHf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Separar X e y do dataframe original (antes do SMOTE)\n",
        "X = dados_normalizados.drop('Churn', axis=1)\n",
        "y = dados_normalizados['Churn']\n"
      ],
      "metadata": {
        "id": "YL_aY0d4zHcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Dividir em dados de treino e teste PRIMEIRO\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.3, random_state=40)"
      ],
      "metadata": {
        "id": "DAXffAFm7kgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibe a distribui√ß√£o normalizada da vari√°vel 'Churn' em percentual\n",
        "churn_distribution = dados_normalizados['Churn'].value_counts(normalize=True) * 100\n",
        "\n",
        "# Exibe os resultados com duas casas decimais\n",
        "print(churn_distribution.apply(lambda x: f'{x:.2f}%'))"
      ],
      "metadata": {
        "id": "iV_-5yKPzHZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Quantidade de NaN em y:\", y.isna().sum())\n",
        "print(\"Total de linhas em y:\", len(y))\n",
        "print(\"Propor√ß√£o de NaN em y:\", y.isna().mean())\n",
        "\n",
        "print(\"\\nVerificando X:\")\n",
        "print(X.isna().sum())  # mostra colunas com NaN\n"
      ],
      "metadata": {
        "id": "ulhNKWYLBIaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape de X:\", X.shape)\n",
        "print(\"Shape de y:\", y.shape)\n",
        "\n",
        "# Se estiver usando treino/teste\n",
        "print(\"Shape de X_treino:\", X_treino.shape)\n",
        "print(\"Shape de y_treino:\", y_treino.shape)\n"
      ],
      "metadata": {
        "id": "Xl4Dqo88Bv6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Para classifica√ß√£o bin√°ria\n",
        "y = y.fillna(y.mode()[0])  # preenche com a moda (valor mais frequente)\n",
        "y = y.astype(int)           # garante que seja inteiro\n"
      ],
      "metadata": {
        "id": "1lzYXkFaGKfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# =========================\n",
        "# 1Ô∏è‚É£ Fun√ß√£o de valida√ß√£o\n",
        "# =========================\n",
        "def validar_dados(X, y, etapa=\"pr√©-processamento\", parar_em_erro=True):\n",
        "    \"\"\"\n",
        "    Verifica se X e y t√™m dados v√°lidos.\n",
        "    Mostra alertas se estiverem vazios ou com NaN.\n",
        "    \"\"\"\n",
        "    print(f\"\\nüîé Validando dados ap√≥s etapa: {etapa}\")\n",
        "    print(f\"‚û° Shape de X: {X.shape}\")\n",
        "    print(f\"‚û° Shape de y: {y.shape}\")\n",
        "\n",
        "    if X.shape[0] == 0 or y.shape[0] == 0:\n",
        "        msg = f\"‚ùå Dataset vazio ap√≥s {etapa}. Verifique filtros ou origem dos dados.\"\n",
        "        if parar_em_erro:\n",
        "            raise ValueError(msg)\n",
        "        else:\n",
        "            print(msg)\n",
        "            return False\n",
        "\n",
        "    if y.isna().sum() > 0:\n",
        "        print(f\"‚ö†Ô∏è Aten√ß√£o: y cont√©m {y.isna().sum()} valores NaN.\")\n",
        "\n",
        "    na_x = X.isna().sum()\n",
        "    if na_x.sum() > 0:\n",
        "        print(\"‚ö†Ô∏è Aten√ß√£o: X cont√©m valores NaN nas colunas abaixo:\")\n",
        "        print(na_x[na_x > 0])\n",
        "\n",
        "    print(\"‚úÖ Dados v√°lidos!\")\n",
        "    return True\n",
        "\n",
        "# =========================\n",
        "# 2Ô∏è‚É£ Exemplo de dados\n",
        "# =========================\n",
        "# Substitua pelo seu dataset real\n",
        "# df = pd.read_csv(\"seus_dados.csv\")\n",
        "# X = df.drop(\"target\", axis=1)\n",
        "# y = df[\"target\"]\n",
        "\n",
        "X = pd.DataFrame({\n",
        "    \"A\": [1, 2, 3, None, 5],\n",
        "    \"B\": [5, 4, None, 2, 1]\n",
        "})\n",
        "y = pd.Series([0, 1, None, 0, 1])\n",
        "\n",
        "# =========================\n",
        "# 3Ô∏è‚É£ Tratar NaN\n",
        "# =========================\n",
        "X = X.fillna(X.median())\n",
        "y = y.fillna(y.median())\n",
        "\n",
        "# =========================\n",
        "# 4Ô∏è‚É£ Validar dados\n",
        "# =========================\n",
        "validar_dados(X, y, etapa=\"ap√≥s tratamento de NaN\")\n",
        "\n",
        "# =========================\n",
        "# 5Ô∏è‚É£ Divis√£o treino/teste\n",
        "# =========================\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "validar_dados(X_treino, y_treino, etapa=\"train_test_split\")\n",
        "\n",
        "# =========================\n",
        "# 6Ô∏è‚É£ Aplicar SMOTE\n",
        "# =========================\n",
        "smote = SMOTE(random_state=42)\n",
        "X_treino_res, y_treino_res = smote.fit_resample(X_treino, y_treino)\n",
        "\n",
        "print(f\"\\n‚úÖ SMOTE aplicado com sucesso! Novo shape treino: {X_treino_res.shape}\")\n"
      ],
      "metadata": {
        "id": "umwmvu8IFp_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Remove valores NaN em y (e nas linhas correspondentes de X)\n",
        "mask = ~pd.isna(y)   # mant√©m apenas onde y N√ÉO √© NaN\n",
        "X = X.loc[mask]\n",
        "y = y.loc[mask]\n",
        "\n",
        "# (Opcional) Se preferir preencher em vez de remover, use:\n",
        " #y = y.fillna(y.median())\n",
        "\n",
        "# Definir seed\n",
        "seed = 100\n",
        "\n",
        "# Balanceamento com SMOTE\n",
        "smote_bal = SMOTE(random_state=seed)\n",
        "X_treino_res, y_treino_res = smote_bal.fit_resample(X, y)\n",
        "\n",
        "print(\"‚úÖ Dados balanceados com SMOTE sem valores NaN!\")\n"
      ],
      "metadata": {
        "id": "SbhKKXlY_Pj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pd.isna(y).sum())"
      ],
      "metadata": {
        "id": "CUhhgXNL9V9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = pd.isna(y)\n",
        "X = X[mask]\n",
        "y = y[mask]\n"
      ],
      "metadata": {
        "id": "NwfGFE5W9pdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = y.fillna(y.median())   # ou y.mean(), ou outro valor adequado\n"
      ],
      "metadata": {
        "id": "jJh-Cy_Q93Nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Aplicar o SMOTE APENAS nos dados de treino\n",
        "seed = 100\n",
        "smote_bal = SMOTE(random_state=seed)\n",
        "X_treino_res, y_treino_res = smote_bal.fit_resample(X_treino, y_treino)"
      ],
      "metadata": {
        "id": "jX4TbopgzHWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDistribui√ß√£o das classes ap√≥s o balanceamento:\")\n",
        "print(y.value_counts())\n",
        "\n",
        "# Exibe o n√∫mero de amostras antes e depois\n",
        "print(f\"\\nN√∫mero de amostras antes do balanceamento: {len(y)}\")\n",
        "print(f\"N√∫mero de amostras ap√≥s o balanceamento: {len(y)}\")"
      ],
      "metadata": {
        "id": "tGWGJYdKzHUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Range de valores de k que iremos testar\n",
        "kVals = range(3, 10, 2)\n",
        "\n",
        "# Lista vazia para receber as acur√°cias\n",
        "acuracias = []\n",
        "start = time.time()\n",
        "\n",
        "# Loop para treinar e avaliar o modelo para cada valor de k\n",
        "for k in kVals:\n",
        "    # Treinando o modelo KNN com cada valor de k\n",
        "    modeloKNN = KNeighborsClassifier(n_neighbors=k)\n",
        "    modeloKNN.fit(X_treino_res, y_treino_res)\n",
        "\n",
        "    # Avaliando o modelo e atualizando a lista de acur√°cias\n",
        "    score = modeloKNN.score(X_teste, y_teste)\n",
        "    print(f\"Com valor de k = {k}, a acur√°cia √© = {score * 100:.2f}%\")\n",
        "    acuracias.append(score)\n",
        "\n",
        "# Obtendo o valor de k que apresentou a maior acur√°cia\n",
        "i = np.argmax(acuracias)\n",
        "print(f\"\\nO valor de k = {kVals[i]} alcan√ßou a mais alta acur√°cia de {acuracias[i] * 100:.2f}% nos dados de valida√ß√£o!\")\n",
        "\n",
        "end = time.time()\n",
        "print('Tempo de Treinamento do Modelo:', end - start)\n",
        "\n",
        "# Criando a vers√£o final do modelo com o maior valor de k\n",
        "modeloFinal = KNeighborsClassifier(n_neighbors=kVals[i])\n",
        "modeloFinal.fit(X_treino, y_treino)\n",
        "\n",
        "# Previs√µes com os dados de teste\n",
        "previsoes = modeloFinal.predict(X_teste)\n",
        "\n",
        "# Calculando a acur√°cia do modelo final\n",
        "acuracia = accuracy_score(y_teste, previsoes)\n",
        "\n",
        "# Exibindo a acur√°cia formatada em percentual\n",
        "print(f'Acur√°cia do modelo final: {acuracia * 100:.2f}%')\n"
      ],
      "metadata": {
        "id": "YysQZ6q-zHRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciar e treinar\n",
        "lr = LogisticRegression(random_state=42)\n",
        "lr.fit(X_treino_res, y_treino_res)\n",
        "\n",
        "# Previs√µes\n",
        "y_pred_lr = lr.predict(X_teste)\n",
        "y_prob_lr = lr.predict_proba(X_teste)[:, 1]\n",
        "\n",
        "# Avalia√ß√£o\n",
        "print(\"Regress√£o Log√≠stica\")\n",
        "print(\"Acur√°cia:\", accuracy_score(y_teste, y_pred_lr))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_teste, y_prob_lr))\n",
        "print(\"Matriz de Confus√£o:\\n\", confusion_matrix(y_teste, y_pred_lr))\n",
        "print(classification_report(y_teste, y_pred_lr))"
      ],
      "metadata": {
        "id": "Rc0MVsDG4azm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Defini√ß√£o do modelo base\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Grade de par√¢metros para testar\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],       # n√∫mero de √°rvores\n",
        "    'max_depth': [10, 20],        # profundidade m√°xima da √°rvore\n",
        "    'min_samples_split': [2, 5, 10],       # m√≠nimo de amostras para dividir um n√≥\n",
        "    'min_samples_leaf': [1, 2, 4],         # m√≠nimo de amostras por folha\n",
        "    'max_features': ['sqrt', 'log2']       # como selecionar features em cada divis√£o\n",
        "}\n",
        "\n",
        "# Busca em grade com valida√ß√£o cruzada\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,                     # 5-fold cross validation\n",
        "    scoring='roc_auc',        # m√©trica alvo\n",
        "    n_jobs=-1,                 # usar todos os n√∫cleos dispon√≠veis\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Treinamento\n",
        "grid_search.fit(X_treino_res, y_treino_res)\n",
        "\n",
        "print(\"Melhores par√¢metros encontrados:\")\n",
        "print(grid_search.best_params_)\n",
        "print(\"Melhor pontua√ß√£o ROC AUC:\", grid_search.best_score_)\n"
      ],
      "metadata": {
        "id": "aonn8k6K4awE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\" üéØ MELHOR MODELO PARA ESTA AN√ÅLISE üéØ \".center(60, \" \"))\n",
        "print(\"=\"*60)\n",
        "print(\"\\nüìå Modelo escolhido: RandomForestClassifier\")\n",
        "print(f\"üîπ Melhores par√¢metros: {best_params}\")\n",
        "print(f\"üìä Melhor ROC AUC: {best_score:.4f}\")\n",
        "print(\"\\n‚úÖ Este modelo apresentou a melhor performance entre os testados e ser√° utilizado para as pr√≥ximas etapas da an√°lise.\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "BPPLgOKy4atP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AgTyqYTn4aqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OXH0sYVD4ann"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Oe93IFwR4akk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ef5pNFax4aKS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}